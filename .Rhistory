install.packages("KoNLP")
install.packages("readr")
install.packages("foreach")
install.packages("doParallel")
library(KoNLP)      # 한국어 품사태깅
library(stringr)    # R 정규표현식
library(readr)      # DataFrame reader
library(foreach)    # 병렬처리 반복문
library(doParallel) # 멀티코어 병렬처리 지원
useNIADic() # NIADic 사용
setwd("d:/works/project/phone_csf") # 작업경로 지정
ko_tokenizer = function(x) {
sentence = as.character(x)
sentence = gsub('[-,~?!.&;]', ' ', sentence)
pos = paste(MorphAnalyzer(sentence))
## 품사별 추출
extracted = str_match(pos, '([ㄱ-ㅎ가-힣A-z0-9]+)/(paa|ncps|pvg)')
len.analyzer = length(extracted[,1])
## 추출 키워드 통합
if (len.analyzer == 0) {
keyword = "none"
return(keyword)
}
else {
keyword = c(extracted[1:len.analyzer,2])
keyword = keyword[!is.na(keyword)]
keyword = paste(keyword, collapse = " ")
keyword = gsub('[:^:]', '', keyword)
return(keyword)
}
}    # 일반단어 추출용
ko_tokenizer2 = function(x) {
sentence = as.character(x)
sentence = gsub('[-,~?!.&;]', ' ', sentence)
pos = paste(MorphAnalyzer(sentence))
## 품사별 추출
extracted = str_match(pos, '([ㄱ-ㅎ가-힣A-z0-9]+)/(f|ncn|ncpa|ncps|paa)')
len.analyzer = length(extracted[,1])
## 추출 키워드 통합
if (len.analyzer == 0) {
keyword = "none"
return(keyword)
}
else {
keyword = c(extracted[1:len.analyzer,2])
keyword = keyword[!is.na(keyword)]
keyword = paste(keyword, collapse = " ")
keyword = gsub('[:^:]', '', keyword)
return(keyword)
}
}    # 일반단어 추출용
senti_tokenizer = function(x) {
sentence = as.character(x)
sentence = gsub('[-,~?!.&;]', ' ', sentence)
pos = paste(MorphAnalyzer(sentence))
## 품사별 추출
extracted = str_match(pos, '([가-힣]+)/(ncpa|ncps|paa|pvg|nqq)')
len.analyzer = length(extracted[,1])
## 추출 키워드 통합
if (len.analyzer == 0) {
keyword = "none"
return(keyword)
}
else {
keyword = c(extracted[1:len.analyzer,2])
keyword = keyword[!is.na(keyword)]
keyword = paste(keyword, collapse = " ")
return(keyword)
}
} # 감정단어 추출용
kotok = function(df) {
filtered_df = list()
count = 0
for (i in seq(df)) {
filtered = ko_tokenizer(df[i])
filtered_df = append(filtered, filtered_df)
count = count + 1
cat('Tokenizer is working... ', count, (count/length(df))*100, '% completed', '\n')
}
return(filtered_df)
}  # 문서 일반단어 추출
sentok = function(df) {
filtered_df = list()
count = 0
for (i in seq(df)) {
filtered = senti_tokenizer(df[i])
filtered_df = append(filtered, filtered_df)
count = count + 1
cat('Tokenizer is working... ', count, (count/length(df))*100, '% completed', '\n')
}
return(filtered_df)
} # 문서 감정단어 추출
kotok_parel = function(df) {
filtered_df = foreach(i = 1:length(df),
.combine = rbind,
.errorhandling='pass',
.packages = c('KoNLP', 'stringr'),
.export = 'ko_tokenizer') %dopar% {
filtered = ko_tokenizer(df[i])
}
}    # 문서 일반단어 추출(Parel)
sentok_parel = function(df) {
filtered_df = foreach(i = 1:length(df),
.combine = rbind,
.errorhandling='pass',
.packages = c('KoNLP', 'stringr'),
.export = 'senti_tokenizer') %dopar% {
filtered = senti_tokenizer(df[i])
}
}   # 문서 감정단어 추출(Parel)
raw_data = read_delim('D:/works/project/phone_csf/dataframes/phone_fullframe.csv', '\t') # DataFrame 로딩
work_dic = "D:\Doucument\project\phone_csf"
work_dic = "D:/Doucument/project/phone_csf"
setwd(work_dic) # 작업경로 지정
raw_data = read_delim('/dataframes/phone_fullframe.csv', '\t') # DataFrame 로딩
raw_data = read_delim('./dataframes/phone_fullframe.csv', '\t') # DataFrame 로딩
View(raw_data)
View(raw_data)
phone_text = subset(raw_data, select=c("title", "content")) # DataFrame 제목, 내용 병합
phone_text = paste(phone_text$title, phone_text$content)
extracted = str_match(pos, '([ㄱ-ㅎ가-힣A-z0-9]+)/(f|ncn|ncpa|ncps|paa|pvg)')
ko_tokenizer2 = function(x) {
sentence = as.character(x)
sentence = gsub('[-,~?!.&;]', ' ', sentence)
pos = paste(MorphAnalyzer(sentence))
## 품사별 추출
extracted = str_match(pos, '([ㄱ-ㅎ가-힣A-z0-9]+)/(f|ncn|ncpa|ncps|paa|pvg)')
len.analyzer = length(extracted[,1])
## 추출 키워드 통합
if (len.analyzer == 0) {
keyword = "none"
return(keyword)
}
else {
keyword = c(extracted[1:len.analyzer,2])
keyword = keyword[!is.na(keyword)]
keyword = paste(keyword, collapse = " ")
keyword = gsub('[:^:]', '', keyword)
return(keyword)
}
}    # 일반단어 추출용
kotok = function(df) {
filtered_df = list()
count = 0
for (i in seq(df)) {
filtered = ko_tokenizer2(df[i])
filtered_df = append(filtered, filtered_df)
count = count + 1
cat('Tokenizer is working... ', count, (count/length(df))*100, '% completed', '\n')
}
return(filtered_df)
}  # 문서 일반단어 추출
ko_df = as.matrix(kotok(phone_text))
library(KoNLP)      # 한국어 품사태깅
install.packages("rJava")
library(KoNLP)      # 한국어 품사태깅
library(KoNLP)      # 한국어 품사태깅
library(stringr)    # R 정규표현식
library(readr)      # DataFrame reader
library(foreach)    # 병렬처리 반복문
library(doParallel) # 멀티코어 병렬처리 지원
ko_df = as.matrix(kotok(phone_text))
View(ko_df)
View(raw_data)
View(ko_df)
View(raw_data)
raw_data$contents = paste(raw_data$title, ' ', raw_data$content)
View(raw_data)
raw_data$title = NULL
raw_data$content = NULL
View(raw_data)
kotok = function(df) {
#filtered_df = list()
count = 0
for (i in seq(df)) {
filtered = ko_tokenizer2(df[i])
#filtered_df = append(filtered, filtered_df)
count = count + 1
cat('Tokenizer is working... ', count, (count/length(df))*100, '% completed', '\n')
}
return(filtered)
}  # 문서 일반단어 추출
raw_data$contents = kotok(raw_data$contents)
View(raw_data)
seq(raw_data$contents)
raw_data$contents[0]
raw_data$contents[1]
raw_data$contents[2]
raw_data = read_delim('./dataframes/phone_fullframe.csv', '\t') # DataFrame 로딩
raw_data$contents = paste(raw_data$title, ' ', raw_data$content)
raw_data$title = NULL
raw_data$content = NULL
raw_data$contents[1]
raw_data$contents[2]
seq(10)
for (i in seq(10)) {
raw_data$contents[i] = kotok(raw_data$contents)
}
View(raw_data)
kotok = function(df) {
#filtered_df = list()
count = 0
for (i in seq(10)) {
filtered = ko_tokenizer2(df[i])
#filtered_df = append(filtered, filtered_df)
count = count + 1
cat('Tokenizer is working... ', count, (count/length(df))*100, '% completed', '\n')
}
return(filtered)
}  # 문서 일반단어 추출
raw_data = read_delim('./dataframes/phone_fullframe.csv', '\t') # DataFrame 로딩
raw_data$contents = paste(raw_data$title, ' ', raw_data$content)
raw_data$title = NULL
raw_data$content = NULL
for (i in seq(10)) {
raw_data$contents[i] = kotok(raw_data$contents)
}
View(raw_data)
raw_data = read_delim('./dataframes/phone_fullframe.csv', '\t') # DataFrame 로딩
raw_data$contents = paste(raw_data$title, ' ', raw_data$content)
raw_data$title = NULL
raw_data$content = NULL
for (i in seq(10)) {
raw_data$contents[i] = ko_tokenizer2(raw_data$contents[i])
}
View(raw_data)
raw_data = read_delim('./dataframes/phone_fullframe.csv', '\t') # DataFrame 로딩
raw_data$contents = paste(raw_data$title, ' ', raw_data$content)
raw_data$title = NULL
raw_data$content = NULL
View(raw_data)
ko_tokenizer = function(x) {
sentence = as.character(x)
sentence = gsub('[-,~?!.&;]', ' ', sentence)
pos = paste(MorphAnalyzer(sentence))
## 품사별 추출
extracted = str_match(pos, '([ㄱ-ㅎ가-힣A-z0-9]+)/(f|ncn|ncpa|ncps|paa|pvg)')
len.analyzer = length(extracted[,1])
## 추출 키워드 통합
if (len.analyzer == 0) {
keyword = "none"
return(keyword)
}
else {
keyword = c(extracted[1:len.analyzer,2])
keyword = keyword[!is.na(keyword)]
keyword = paste(keyword, collapse = " ")
keyword = gsub('[:^:]', '', keyword)
return(keyword)
}
}    # 일반단어 추출용
raw_data = read_delim('./dataframes/phone_fullframe.csv', '\t') # DataFrame 로딩
raw_data$contents = paste(raw_data$title, ' ', raw_data$content)
raw_data$title = NULL
raw_data$content = NULL
for (i in seq(10)) {
count = 0
raw_data$contents[i] = ko_tokenizer2(raw_data$contents[i])
count = count + 1
cat('Tokenizer is working... ', count, (count/length(raw_data$contents))*100, '% completed', '\n')
}
raw_data = read_delim('./dataframes/phone_fullframe.csv', '\t') # DataFrame 로딩
raw_data$contents = paste(raw_data$title, ' ', raw_data$content)
raw_data$title = NULL
raw_data$content = NULL
raw_data = read_delim('./dataframes/phone_fullframe.csv', '\t') # DataFrame 로딩
raw_data$contents = paste(raw_data$title, ' ', raw_data$content)
raw_data$title = NULL
raw_data$content = NULL
for (i in seq(raw_data$contents)) {
count = 0
raw_data$contents[i] = ko_tokenizer(raw_data$contents[i])
count = count + 1
cat('Tokenizer is working... ', count, (count/length(raw_data$contents))*100, '% completed', '\n')
}
length(raw_data$contents)
View(raw_data)
raw_data = read_delim('./dataframes/phone_fullframe.csv', '\t') # DataFrame 로딩
raw_data$contents = paste(raw_data$title, ' ', raw_data$content)
raw_data$title = NULL
raw_data$content = NULL
count = 0
for (i in seq(raw_data$contents)) {
raw_data$contents[i] = ko_tokenizer(raw_data$contents[i])
count = count + 1
cat('Tokenizer is working... ', count, (count/length(raw_data$contents))*100, '% completed', '\n')
}
View(raw_data)
write.csv(raw_data, file="./dataframes/pcsf_dataframe(ap).csv", row.names = F, col.names = T)
